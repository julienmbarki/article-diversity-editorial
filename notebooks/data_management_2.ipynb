{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df_afro.xlsx')\n",
    "\n",
    "# Group by playlist name\n",
    "groups = df.groupby('playlist_name')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Store optimal number of components for each group\n",
    "optimal_num_components = []\n",
    "\n",
    "for group_name, group in groups:\n",
    "    # Subset data\n",
    "    subset = group.loc[:, \"danceability\":\"duration_ms\"]\n",
    "    \n",
    "    # Scale the specified columns\n",
    "    scaled_columns = scaler.fit_transform(subset)\n",
    "\n",
    "    # Perform PCA to reduce dimensionality of data\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_columns)\n",
    "    \n",
    "    # Determine the optimal number of components\n",
    "    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "    optimal_components = next(i for i, var in enumerate(cumulative_variance) if var >= 0.8) + 1\n",
    "    optimal_num_components.append(optimal_components)\n",
    "\n",
    "    # Plot scree plot\n",
    "    plt.plot(range(1, pca.n_components_ + 1), cumulative_variance, 'bo-', linewidth=2)\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.title(group_name)\n",
    "    plt.show()\n",
    "\n",
    "# Calculate the most modal value\n",
    "most_common_optimal = Counter(optimal_num_components).most_common(1)\n",
    "most_modal_value = most_common_optimal[0][0]\n",
    "\n",
    "print(\"Most modal value of optimal components:\", most_modal_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each group and apply PCA with optimal number of components\n",
    "reduced_data_dict = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "    # Subset data\n",
    "    subset = group.loc[:, \"danceability\":\"duration_ms\"]\n",
    "\n",
    "    # Scale the specified columns\n",
    "    scaled_columns = scaler.fit_transform(subset)\n",
    "\n",
    "    # Apply PCA with the optimal number of components\n",
    "    n_components = 6\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(scaled_columns)\n",
    "    reduced_data_dict[group_name] = reduced_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the elbow method to determine the optimal number of clusters\n",
    "wcss = {}\n",
    "\n",
    "for k in range(1, 11):\n",
    "  for group_name, group in groups:\n",
    "    reduced_data = reduced_data_dict[group_name]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(reduced_data)\n",
    "    \n",
    "    if group_name not in wcss:\n",
    "      wcss[group_name] = []\n",
    "\n",
    "    wcss[group_name].append(kmeans.inertia_)\n",
    "\n",
    "for group_name, values in wcss.items():\n",
    "  plt.plot(range(1, 11), values, label=group_name)\n",
    "  plt.xlabel('Number of clusters (k)')\n",
    "  plt.ylabel('Within-cluster sum of squares (WCSS)')\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gap statistic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap(data, k):\n",
    "  \"\"\"\n",
    "  Compute the gap statistic for a given value of k.\n",
    "\n",
    "  Parameters:\n",
    "  - data: the data to cluster, with shape (n_samples, n_features)\n",
    "  - k: the number of clusters\n",
    "\n",
    "  Returns:\n",
    "  - gap: the gap statistic for the given value of k\n",
    "  \"\"\"\n",
    "  # Compute the WCSS for the real data\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42).fit(data)\n",
    "  wcss = kmeans.inertia_\n",
    "\n",
    "  # Compute the null reference distribution by shuffling the data and\n",
    "  # re-assigning it to clusters\n",
    "  n_samples, n_features = data.shape\n",
    "  wcss_null = []\n",
    "\n",
    "  for _ in range(20):\n",
    "    data_shuffled = np.random.permutation(data)\n",
    "    wcss_null.append(KMeans(n_clusters=k).fit(data_shuffled).inertia_)\n",
    "  \n",
    "  wcss_null = np.array(wcss_null)\n",
    "  \n",
    "  # Compute the gap statistic and gap*\n",
    "  gap = np.log(np.mean(wcss_null)) - np.log(wcss)\n",
    "\n",
    "  # Compute the standard deviation of the null reference distribution\n",
    "  gap_std = np.std(np.log(wcss_null))\n",
    "\n",
    "  return gap, gap_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each group and generate scree plot\n",
    "optimal_num_k = {}\n",
    "optimal_num_k_2 = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "    # Initialize lists to store the gap statistics and error bars for different values of k\n",
    "    group_gaps = []\n",
    "    group_errors = []\n",
    "\n",
    "    # Loop over different values of k\n",
    "    for k in range(1, 11):\n",
    "        reduced_data = reduced_data_dict[group_name]\n",
    "\n",
    "        # Compute the gap statistic and standard deviation for the current value of k\n",
    "        gap, gap_std = compute_gap(reduced_data, k)\n",
    "        group_gaps.append(gap)\n",
    "        group_errors.append(gap_std)\n",
    "\n",
    "    # Find the optimal number of components based on the gap statistic criterion\n",
    "    optimal_k = None\n",
    "    for i in range(1, len(group_gaps) - 1):\n",
    "        s_k = group_errors[i]\n",
    "        threshold = s_k * np.sqrt(1 + 1 / 20)\n",
    "        if group_gaps[i] >= group_gaps[i + 1] - threshold:\n",
    "            optimal_k = i + 1\n",
    "            break\n",
    "\n",
    "    if optimal_k is None:\n",
    "        optimal_k = np.argmax(group_gaps) + 1\n",
    "\n",
    "    optimal_num_k[group_name] = optimal_k\n",
    "\n",
    "    # Find the optimal number of components based on the gap* statistic criterion\n",
    "    optimal_k_2 = np.argmax(group_gaps) + 1\n",
    "\n",
    "    optimal_num_k_2[group_name] = optimal_k_2\n",
    "\n",
    "    # Plot the gap statistics\n",
    "    plt.plot(range(1, 11), group_gaps, label=group_name)\n",
    "\n",
    "    # Set labels and display the plot\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Gap statistic')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Group: {group_name}, Optimal k (gap): {optimal_num_k[group_name]}, Optimal k (gap*): {optimal_num_k_2[group_name]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop over each group and apply KMeans with optimal number of clusters\n",
    "kmeans_dict = {}\n",
    "kmeans_2_dict = {}\n",
    "cluster_labels_dict = {}\n",
    "cluster_labels_2_dict = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "    # Get reduced data\n",
    "    reduced_data = reduced_data_dict[group_name]\n",
    "\n",
    "    # Get optimal number of clusters\n",
    "    k = optimal_num_k[group_name]\n",
    "    k_2 = optimal_num_k_2[group_name]\n",
    "\n",
    "    # Apply KMeans with optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(reduced_data)\n",
    "    kmeans_2 = KMeans(n_clusters=k_2, random_state=42).fit(reduced_data)\n",
    "    \n",
    "    # Store KMeans object in dictionary\n",
    "    kmeans_dict[group_name] = kmeans\n",
    "    kmeans_2_dict[group_name] = kmeans_2\n",
    "\n",
    "    cluster_labels_dict[group_name] = kmeans.labels_\n",
    "    cluster_labels_2_dict[group_name] = kmeans_2.labels_\n",
    "\n",
    "    # Print cluster labels\n",
    "    print(f\"Group {group_name}: {kmeans.labels_}\")\n",
    "\n",
    "    # Assign cluster labels to original group data\n",
    "    group = group.assign(cluster=kmeans.labels_)\n",
    "    group = group.assign(cluster_2=kmeans_2.labels_)\n",
    "\n",
    "    # Append group to original dataframe\n",
    "    df = pd.concat([df, group])\n",
    "    \n",
    "    # Plot clusters\n",
    "    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title(group_name)\n",
    "    plt.show()\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('playlist_name')\n",
    "\n",
    "shares_perc = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "    shares = group['cluster'].value_counts(normalize=True)\n",
    "    shares_perc[group_name] = shares * 100\n",
    "\n",
    "print(shares_perc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HH-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('playlist_name')\n",
    "\n",
    "hhi = {}\n",
    "hhi_2 = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "  shares = group['cluster'].value_counts(normalize=True)\n",
    "  shares_2 = group['cluster_2'].value_counts(normalize=True)\n",
    "\n",
    "  hhi[group_name] = sum((shares*100)**2)\n",
    "  hhi_2[group_name] = sum((shares_2*100)**2)\n",
    "\n",
    "print(hhi)\n",
    "print (hhi_2)\n",
    "\n",
    "print(\"Minimum HHI: \", min(hhi.values()))\n",
    "print(\"Mean HHI: \", np.mean(list(hhi.values())))\n",
    "print(\"Median HHI: \", np.median(list(hhi.values())))\n",
    "print(\"Maximum HHI: \", max(hhi.values()))\n",
    "print(\"Standard deviation: \", np.std(list(hhi.values())))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# loop over each playlist and compute the weighted Stirling index\n",
    "for group_name, group in df.groupby('playlist_name'):\n",
    "    # Subset data\n",
    "    subset = group.loc[:, \"danceability\":\"duration_ms\"]\n",
    "\n",
    "    # Scale the specified columns\n",
    "    scaled_columns = scaler.fit_transform(subset)\n",
    "\n",
    "    # Calculate pairwise euclidean distances between cluster centroids\n",
    "    distances = pairwise_distances(scaled_columns)\n",
    "\n",
    "    # Calculate mean pairwise distance\n",
    "    mean_distance = distances.mean()\n",
    "\n",
    "    # get all info\n",
    "    nb_artists = len(group['artist_name'].unique())\n",
    "    hh_index = hhi[group_name]\n",
    "    hh_index_2 = hhi_2[group_name]\n",
    "    playlist_followers = group['playlist_followers'].iloc[0]\n",
    "    track_popularity = group['popularity_track'].mean()\n",
    "    artist_popularity = group['popularity_artist'].mean()\n",
    "    nb_tracks = len(group)\n",
    "    nb_clusters = optimal_num_k[group_name]\n",
    "    nb_clusters_2 = optimal_num_k_2[group_name]\n",
    "    \n",
    "\n",
    "    results_df = results_df.append({'playlist_name': group_name, 'playlist_followers': playlist_followers,\n",
    "                                    'track_pop': track_popularity, 'artist_pop': artist_popularity,\n",
    "                                    'nb_tracks': nb_tracks, 'nb_artists': nb_artists, 'nb_dimensions':n_components, \n",
    "                                    'nb_clusters': nb_clusters, 'nb_clusters_2': nb_clusters_2,\n",
    "                                    'hhi': hh_index, 'hhi_2': hh_index_2, 'mean_distance': mean_distance},\n",
    "                                   ignore_index=True)\n",
    "\n",
    "\n",
    "# print the results dataframe\n",
    "print(results_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse final results into excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"df_detente_final_2.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robustness checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df_electro.xlsx')\n",
    "\n",
    "# Group by playlist name\n",
    "groups = df.groupby('playlist_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Initialize dictionaries to store clustering results\n",
    "reduced_data_dict_5 = {}\n",
    "reduced_data_dict_4 = {}\n",
    "\n",
    "# Loop over each group and apply PCA with the specified number of components\n",
    "for group_name, group in groups:\n",
    "    # Subset data\n",
    "    subset = group.loc[:, \"danceability\":\"duration_ms\"]\n",
    "\n",
    "    scaled_columns = scaler.fit_transform(subset)\n",
    "\n",
    "    # Apply PCA with 5 dimensions\n",
    "    pca_5 = PCA(n_components=5)\n",
    "    reduced_data_5 = pca_5.fit_transform(scaled_columns)\n",
    "\n",
    "    # Apply PCA with 4 dimensions\n",
    "    pca_4 = PCA(n_components=4)\n",
    "    reduced_data_4 = pca_4.fit_transform(scaled_columns)\n",
    "\n",
    "    reduced_data_dict_5[group_name] = reduced_data_5\n",
    "    reduced_data_dict_4[group_name] = reduced_data_4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap(data, k):\n",
    "  \"\"\"\n",
    "  Compute the gap statistic for a given value of k.\n",
    "\n",
    "  Parameters:\n",
    "  - data: the data to cluster, with shape (n_samples, n_features)\n",
    "  - k: the number of clusters\n",
    "\n",
    "  Returns:\n",
    "  - gap: the gap statistic for the given value of k\n",
    "  \"\"\"\n",
    "  # Compute the WCSS for the real data\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42).fit(data)\n",
    "  wcss = kmeans.inertia_\n",
    "\n",
    "  # Compute the null reference distribution by shuffling the data and\n",
    "  # re-assigning it to clusters\n",
    "  n_samples, n_features = data.shape\n",
    "  wcss_null = []\n",
    "\n",
    "  for _ in range(20):\n",
    "    data_shuffled = np.random.permutation(data)\n",
    "    wcss_null.append(KMeans(n_clusters=k).fit(data_shuffled).inertia_)\n",
    "  \n",
    "  wcss_null = np.array(wcss_null)\n",
    "  \n",
    "  # Compute the gap statistic and gap*\n",
    "  gap = np.log(np.mean(wcss_null)) - np.log(wcss)\n",
    "\n",
    "  # Compute the standard deviation of the null reference distribution\n",
    "  gap_std = np.std(np.log(wcss_null))\n",
    "\n",
    "  return gap, gap_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: 80s Dance Hits, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: 90s Dance Party, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 9\n",
      "Group: AMAPIANO grooves, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 8\n",
      "Group: Altar, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 7\n",
      "Group: Banger, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 6\n",
      "Group: Big Room Dance, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 3 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 10\n",
      "Group: Chill Tracks, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 8\n",
      "Group: Dance Classics, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 8\n",
      "Group: Dance Hits, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 8 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: Dance Hits 2000s, Optimal k 5 (gap): 4, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 9\n",
      "Group: Dance Hits 2010s, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 6\n",
      "Group: Dance Hits of 2010, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 5 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 7\n",
      "Group: Dance Hits of 2011, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 6\n",
      "Group: Dance Hits of 2012, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 5 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: Dance Hits of 2013, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 9\n",
      "Group: Dance Hits of 2014, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 8 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 9\n",
      "Group: Dance Hits of 2015, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 9\n",
      "Group: Dance Hits of 2016, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 6\n",
      "Group: Dance Hits of 2017, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 9\n",
      "Group: Dance Hits of 2018, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: Dance Hits of 2019, Optimal k 5 (gap): 4, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 8\n",
      "Group: Dance Party, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 3\n",
      "Group: Dance Rising, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 5, Optimal k 4 (gap*): 9\n",
      "Group: Dancefloor Classics, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 9\n",
      "Group: Electro Mix, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: Electronic Circus, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 8 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 7\n",
      "Group: French Touch, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 5 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 10\n",
      "Group: French Touch 2.0, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 4 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 9\n",
      "Group: Fresh Touch, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 6\n",
      "Group: Hardstyle Remixes, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 4\n",
      "Group: Hit Dancefloor, Optimal k 5 (gap): 4, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 8\n",
      "Group: House is a Feeling, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 7\n",
      "Group: Main Stage, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 5\n",
      "Group: Massive Dance Classics, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 7\n",
      "Group: Nouveautés Electro, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 9 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 6\n",
      "Group: Techno Bunker, Optimal k 5 (gap): 4, Optimal k 4 (gap*): 8 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 9\n",
      "Group: Tomorrowland Essentials, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 7 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 6\n",
      "Group: Umami, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 10\n",
      "Group: indelectro, Optimal k 5 (gap): 4, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 4, Optimal k 4 (gap*): 7\n",
      "Group: mint, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 10 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 6\n",
      "Group: mint Acoustic, Optimal k 5 (gap): 2, Optimal k 4 (gap*): 8 and Optimal k 4 (gap): 2, Optimal k 4 (gap*): 9\n",
      "Group: phonk, Optimal k 5 (gap): 3, Optimal k 4 (gap*): 6 and Optimal k 4 (gap): 3, Optimal k 4 (gap*): 10\n"
     ]
    }
   ],
   "source": [
    "# Loop over each group and generate scree plot\n",
    "optimal_num_k_pca_5 = {}\n",
    "optimal_num_k_2_pca_5 = {}\n",
    "\n",
    "optimal_num_k_pca_4 = {}\n",
    "optimal_num_k_2_pca_4 = {}\n",
    "\n",
    "for group_name, group in groups:\n",
    "    # Initialize lists to store the gap statistics and error bars for different values of k\n",
    "    group_gaps_5 = []\n",
    "    group_errors_5 = []\n",
    "\n",
    "    group_gaps_4 = []\n",
    "    group_errors_4 = []\n",
    "\n",
    "    # Loop over different values of k\n",
    "    for k in range(1, 11):\n",
    "        reduced_data_5 = reduced_data_dict_5[group_name]\n",
    "        reduced_data_4 = reduced_data_dict_4[group_name]\n",
    "\n",
    "        # Compute the gap statistic and standard deviation for the current value of k\n",
    "        gap_5, gap_std_5 = compute_gap(reduced_data_5, k)\n",
    "        group_gaps_5.append(gap_5)\n",
    "        group_errors_5.append(gap_std_5)\n",
    "\n",
    "        gap_4, gap_std_4 = compute_gap(reduced_data_4, k)\n",
    "        group_gaps_4.append(gap_4)\n",
    "        group_errors_4.append(gap_std_4)\n",
    "\n",
    "    # Find the optimal number of components based on the gap statistic criterion\n",
    "    optimal_k_5 = None\n",
    "    for i in range(1, len(group_gaps_5) - 1):\n",
    "        s_k = group_errors_5[i]\n",
    "        threshold = s_k * np.sqrt(1 + 1 / 20)\n",
    "        if group_gaps_5[i] >= group_gaps_5[i + 1] - threshold:\n",
    "            optimal_k_5 = i + 1\n",
    "            break\n",
    "\n",
    "    if optimal_k_5 is None:\n",
    "        optimal_k_5 = np.argmax(group_gaps_5) + 1\n",
    "\n",
    "    optimal_num_k_pca_5[group_name] = optimal_k_5\n",
    "\n",
    "    optimal_k_4 = None\n",
    "    for i in range(1, len(group_gaps_4) - 1):\n",
    "        s_k = group_errors_4[i]\n",
    "        threshold = s_k * np.sqrt(1 + 1 / 20)\n",
    "        if group_gaps_4[i] >= group_gaps_4[i + 1] - threshold:\n",
    "            optimal_k_4 = i + 1\n",
    "            break\n",
    "\n",
    "    if optimal_k_4 is None:\n",
    "        optimal_k_4 = np.argmax(group_gaps_4) + 1\n",
    "\n",
    "    optimal_num_k_pca_5[group_name] = optimal_k_5\n",
    "    optimal_num_k_pca_4[group_name] = optimal_k_4\n",
    "\n",
    "    # Find the optimal number of components based on the gap* statistic criterion\n",
    "    optimal_k_2_5 = np.argmax(group_gaps_5) + 1\n",
    "    optimal_k_2_4 = np.argmax(group_gaps_4) + 1\n",
    "\n",
    "    optimal_num_k_2_pca_5[group_name] = optimal_k_2_5\n",
    "    optimal_num_k_2_pca_4[group_name] = optimal_k_2_4\n",
    "\n",
    "    print(f\"Group: {group_name}, Optimal k 5 (gap): {optimal_num_k_pca_5[group_name]}, Optimal k 4 (gap*): {optimal_num_k_2_pca_5[group_name]} and Optimal k 4 (gap): {optimal_num_k_pca_4[group_name]}, Optimal k 4 (gap*): {optimal_num_k_2_pca_4[group_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              playlist_name  nb_cluster_5  nb_cluster_5_2  silhouette_score_5  \\\n",
      "0            80s Dance Hits             2               9            0.215823   \n",
      "1           90s Dance Party             2               6            0.333600   \n",
      "2          AMAPIANO grooves             2               9            0.194626   \n",
      "3                     Altar             2               7            0.370072   \n",
      "4                    Banger             2               9            0.290572   \n",
      "5            Big Room Dance             3               3            0.304428   \n",
      "6              Chill Tracks             3              10            0.301699   \n",
      "7            Dance Classics             2               7            0.383150   \n",
      "8                Dance Hits             2               8            0.297221   \n",
      "9          Dance Hits 2000s             4              10            0.289556   \n",
      "10         Dance Hits 2010s             2               9            0.195942   \n",
      "11       Dance Hits of 2010             3               5            0.307108   \n",
      "12       Dance Hits of 2011             2               7            0.398247   \n",
      "13       Dance Hits of 2012             2               5            0.423216   \n",
      "14       Dance Hits of 2013             2               6            0.195889   \n",
      "15       Dance Hits of 2014             2               8            0.300406   \n",
      "16       Dance Hits of 2015             3               6            0.189216   \n",
      "17       Dance Hits of 2016             2               7            0.219622   \n",
      "18       Dance Hits of 2017             2               9            0.242067   \n",
      "19       Dance Hits of 2018             3               9            0.204856   \n",
      "20       Dance Hits of 2019             4               7            0.209754   \n",
      "21              Dance Party             3               7            0.238072   \n",
      "22             Dance Rising             3              10            0.280552   \n",
      "23      Dancefloor Classics             2              10            0.396639   \n",
      "24              Electro Mix             3               7            0.224193   \n",
      "25        Electronic Circus             2               8            0.289644   \n",
      "26             French Touch             3               5            0.202936   \n",
      "27         French Touch 2.0             2               4            0.270318   \n",
      "28              Fresh Touch             2               7            0.273321   \n",
      "29        Hardstyle Remixes             3               9            0.235750   \n",
      "30           Hit Dancefloor             4              10            0.207005   \n",
      "31       House is a Feeling             3              10            0.255379   \n",
      "32               Main Stage             2               6            0.303827   \n",
      "33   Massive Dance Classics             2               9            0.213393   \n",
      "34       Nouveautés Electro             2               9            0.320249   \n",
      "35            Techno Bunker             4               8            0.223943   \n",
      "36  Tomorrowland Essentials             3               7            0.229612   \n",
      "37                    Umami             2              10            0.303087   \n",
      "38               indelectro             4               6            0.243246   \n",
      "39                     mint             2              10            0.353884   \n",
      "40            mint Acoustic             2               8            0.265353   \n",
      "41                    phonk             3               6            0.307465   \n",
      "\n",
      "    silhouette_score_5_2  nb_cluster_4  nb_cluster_4_2  silhouette_score_4  \\\n",
      "0               0.273732             2              10            0.217028   \n",
      "1               0.240840             3               9            0.244469   \n",
      "2               0.243548             2               8            0.225981   \n",
      "3               0.232632             2               7            0.399111   \n",
      "4               0.260123             2               6            0.311564   \n",
      "5               0.304428             3              10            0.294946   \n",
      "6               0.256196             3               8            0.317276   \n",
      "7               0.236469             4               8            0.266831   \n",
      "8               0.251895             2              10            0.322711   \n",
      "9               0.287233             3               9            0.320397   \n",
      "10              0.177301             3               6            0.237348   \n",
      "11              0.326538             3               7            0.324186   \n",
      "12              0.259050             2               6            0.440715   \n",
      "13              0.263193             2              10            0.447365   \n",
      "14              0.262356             2               9            0.223183   \n",
      "15              0.226252             3               9            0.310934   \n",
      "16              0.229206             4               9            0.249496   \n",
      "17              0.187113             2               6            0.247870   \n",
      "18              0.243067             2               9            0.260736   \n",
      "19              0.201158             2              10            0.212697   \n",
      "20              0.203785             3               8            0.219633   \n",
      "21              0.219988             3               3            0.269678   \n",
      "22              0.228998             5               9            0.263934   \n",
      "23              0.282186             3               9            0.300276   \n",
      "24              0.251797             2              10            0.235868   \n",
      "25              0.232492             2               7            0.290456   \n",
      "26              0.205590             4              10            0.234816   \n",
      "27              0.227144             2               9            0.301676   \n",
      "28              0.222925             2               6            0.308189   \n",
      "29              0.224464             4               4            0.245042   \n",
      "30              0.200588             2               8            0.269271   \n",
      "31              0.221561             2               7            0.309273   \n",
      "32              0.258050             2               5            0.333758   \n",
      "33              0.287652             2               7            0.240253   \n",
      "34              0.302045             4               6            0.316961   \n",
      "35              0.207252             3               9            0.227975   \n",
      "36              0.233195             3               6            0.265283   \n",
      "37              0.233121             2              10            0.332296   \n",
      "38              0.290552             4               7            0.280204   \n",
      "39              0.252416             3               6            0.294363   \n",
      "40              0.234045             2               9            0.289884   \n",
      "41              0.224107             3              10            0.339029   \n",
      "\n",
      "    silhouette_score_4_2  \n",
      "0               0.278596  \n",
      "1               0.244886  \n",
      "2               0.284691  \n",
      "3               0.234598  \n",
      "4               0.304204  \n",
      "5               0.285201  \n",
      "6               0.304219  \n",
      "7               0.287744  \n",
      "8               0.272999  \n",
      "9               0.319344  \n",
      "10              0.237977  \n",
      "11              0.355044  \n",
      "12              0.267343  \n",
      "13              0.318525  \n",
      "14              0.284706  \n",
      "15              0.297256  \n",
      "16              0.264227  \n",
      "17              0.238512  \n",
      "18              0.284200  \n",
      "19              0.237898  \n",
      "20              0.211703  \n",
      "21              0.269678  \n",
      "22              0.247526  \n",
      "23              0.358010  \n",
      "24              0.306973  \n",
      "25              0.272315  \n",
      "26              0.245437  \n",
      "27              0.251591  \n",
      "28              0.282594  \n",
      "29              0.245042  \n",
      "30              0.233388  \n",
      "31              0.246063  \n",
      "32              0.273846  \n",
      "33              0.340099  \n",
      "34              0.300711  \n",
      "35              0.254441  \n",
      "36              0.260342  \n",
      "37              0.251183  \n",
      "38              0.334360  \n",
      "39              0.299417  \n",
      "40              0.247390  \n",
      "41              0.265631  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/41/xvr_rn1j51vd_js7xks_mznh0000gn/T/ipykernel_43148/3039175153.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop over each group and apply PCA with the specified number of components\n",
    "for group_name, group in groups:\n",
    "    # Get reduced data\n",
    "    reduced_data_5 = reduced_data_dict_5[group_name]\n",
    "    reduced_data_4 = reduced_data_dict_4[group_name]\n",
    "\n",
    "    # Perform k-means clustering for both configurations\n",
    "    kmeans_5 = KMeans(n_clusters=optimal_num_k_pca_5[group_name], random_state=42).fit(reduced_data_5)\n",
    "    kmeans_2_5 = KMeans(n_clusters=optimal_num_k_2_pca_5[group_name], random_state=42).fit(reduced_data_5)\n",
    "\n",
    "    kmeans_4 = KMeans(n_clusters=optimal_num_k_pca_4[group_name], random_state=42).fit(reduced_data_4)\n",
    "    kmeans_2_4 = KMeans(n_clusters=optimal_num_k_2_pca_4[group_name], random_state=42).fit(reduced_data_4)\n",
    "\n",
    "    # Get cluster assignments for both configurations\n",
    "    cluster_assignments_5 = kmeans_5.labels_\n",
    "    cluster_assignments_2_5 = kmeans_2_5.labels_\n",
    "\n",
    "    cluster_assignments_4 = kmeans_4.labels_\n",
    "    cluster_assignments_2_4 = kmeans_2_4.labels_\n",
    "\n",
    "    # Compute silhouette scores for both configurations\n",
    "    silhouette_score_5 = silhouette_score(reduced_data_5, cluster_assignments_5)\n",
    "    silhouette_score_2_5 = silhouette_score(reduced_data_5, cluster_assignments_2_5)\n",
    "\n",
    "    silhouette_score_4 = silhouette_score(reduced_data_4, cluster_assignments_4)\n",
    "    silhouette_score_2_4 = silhouette_score(reduced_data_4, cluster_assignments_2_4)\n",
    "\n",
    "    results_df = results_df.append({\n",
    "        'playlist_name': group_name,\n",
    "        'nb_cluster_5': optimal_num_k_pca_5[group_name],\n",
    "        'nb_cluster_5_2': optimal_num_k_2_pca_5[group_name],\n",
    "        'silhouette_score_5': silhouette_score_5,\n",
    "        'silhouette_score_5_2': silhouette_score_2_5,\n",
    "        'nb_cluster_4': optimal_num_k_pca_4[group_name],\n",
    "        'nb_cluster_4_2': optimal_num_k_2_pca_4[group_name],\n",
    "        'silhouette_score_4': silhouette_score_4,\n",
    "        'silhouette_score_4_2': silhouette_score_2_4\n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('robust_electro.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0da26d773aaff631c161613594b6de0a8522876018f5987f12f3dad8e2ed0c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
